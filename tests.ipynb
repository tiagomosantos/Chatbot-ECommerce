{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This document is intended for professor to test individual intention implementations. Each test ensures that specific intents behave as expected when given predefined inputs.\n",
    "\n",
    "## Examples of Messages to Test Each Intention\n",
    "\n",
    "1. **Intent Name**  \n",
    "   _e.g., Retrieve Company Info_\n",
    "\n",
    "2. **Example Inputs**  \n",
    "   - \"Tell me about the company.\"  \n",
    "   - \"What is your mission statement?\"\n",
    "\n",
    "3. **Expected Outputs**  \n",
    "   - \"Our company specializes in renewable energy.\"  \n",
    "   - \"The mission is to provide eco-friendly energy solutions.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intention 1 - Product Information\n",
    "\n",
    "### Example Inputs\n",
    "- \"I am looking for a laptop?\"\n",
    "- \"What products do you offer?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from cobuy.chatbot.memory import MemoryManager\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "user_id = \"1\"\n",
    "conversation_id = \"1\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model=\"gpt-4o-mini\")\n",
    "memory = MemoryManager(user_id, conversation_id)\n",
    "\n",
    "def add_memory_to_chain(original_chain):\n",
    "\n",
    "    new_chain = RunnableWithMessageHistory(\n",
    "                original_chain,\n",
    "                memory.get_session_history,\n",
    "                input_messages_key=\"customer_input\",\n",
    "                history_messages_key=\"chat_history\",\n",
    "                history_factory_config=memory.get_history_factory_config(),\n",
    "            )\n",
    "    return new_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobuy.chatbot.chains.product_info import ProductInfoReasoningChain, ProductInfoResponseChain\n",
    "\n",
    "reasoning_chain = ProductInfoReasoningChain(llm)\n",
    "response_chain = ProductInfoResponseChain(llm)\n",
    "\n",
    "response_chain = add_memory_to_chain(response_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "We offer a wide range of electronics, including:\n",
      "\n",
      "1. **Televisions** - Smart TVs, 4K, OLED, and more.\n",
      "2. **Laptops and Desktops** - Various brands and specifications for personal and professional use.\n",
      "3. **Smartphones and Tablets** - The latest models from top brands.\n",
      "4. **Audio Equipment** - Headphones, speakers, and sound systems.\n",
      "5. **Home Appliances** - Refrigerators, microwaves, and more.\n",
      "6. **Gaming Consoles and Accessories** - PlayStation, Xbox, Nintendo, and gaming peripherals.\n",
      "7. **Wearable Technology** - Smartwatches and fitness trackers.\n",
      "\n",
      "Is there a specific category or product you’re interested in?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! We have several laptops that might fit your needs. Here are a few options:\n",
      "\n",
      "1. **TechPro Ultrabook**\n",
      "   - **Price:** $799.99\n",
      "   - **Features:** 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\n",
      "   - **Description:** A sleek and lightweight ultrabook for everyday use.\n",
      "   - **Rating:** 4.5\n",
      "\n",
      "2. **BlueWave Gaming Laptop**\n",
      "   - **Price:** $1,199.99\n",
      "   - **Features:** 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\n",
      "   - **Description:** A high-performance gaming laptop for an immersive experience.\n",
      "   - **Rating:** 4.7\n",
      "\n",
      "3. **PowerLite Convertible**\n",
      "   - **Price:** $699.99\n",
      "   - **Features:** 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\n",
      "   - **Description:** A versatile convertible laptop with a responsive touchscreen.\n",
      "   - **Rating:** 4.3\n",
      "\n",
      "4. **BlueWave Chromebook**\n",
      "   - **Price:** $249.99\n",
      "   - **Features:** 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\n",
      "   - **Description:** A compact and affordable Chromebook for everyday tasks.\n",
      "   - **Rating:** 4.1\n",
      "\n",
      "Do any of these options catch your eye, or do you have specific requirements in mind, such as budget or intended use?\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Intialize a list of user inputs\n",
    "user_inputs = [\"What products do you offer\", \"I am looking for a laptop\"]\n",
    "\n",
    "\n",
    "for user_input in user_inputs:\n",
    "\n",
    "    user_input = {\"customer_input\": user_input}\n",
    "\n",
    "    # Step 2: Use the user input to get the output from ReasoningChain\n",
    "    reasoning_output = reasoning_chain.invoke(user_input)\n",
    "\n",
    "    # Step 3: Use the output from ReasoningChain to get the response from ResponseChain\n",
    "    response = response_chain.invoke(reasoning_output, memory.get_memory_config())\n",
    "\n",
    "    response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = memory.get_session_history(user_id=user_id, conversation_id=conversation_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryHistory(messages=[HumanMessage(content='What products do you offer', additional_kwargs={}, response_metadata={}), AIMessage(content='We offer a wide range of electronics, including:\\n\\n1. **Televisions** - Smart TVs, 4K, OLED, and more.\\n2. **Laptops and Desktops** - Various brands and specifications for personal and professional use.\\n3. **Smartphones and Tablets** - The latest models from top brands.\\n4. **Audio Equipment** - Headphones, speakers, and sound systems.\\n5. **Home Appliances** - Refrigerators, microwaves, and more.\\n6. **Gaming Consoles and Accessories** - PlayStation, Xbox, Nintendo, and gaming peripherals.\\n7. **Wearable Technology** - Smartwatches and fitness trackers.\\n\\nIs there a specific category or product you’re interested in?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 109, 'total_tokens': 254, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-74aea66f-b0f8-4aea-bac3-6b995edaa62e-0', usage_metadata={'input_tokens': 109, 'output_tokens': 145, 'total_tokens': 254, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='I am looking for a laptop', additional_kwargs={}, response_metadata={}), AIMessage(content='Great! We have several laptops that might fit your needs. Here are a few options:\\n\\n1. **TechPro Ultrabook**\\n   - **Price:** $799.99\\n   - **Features:** 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\\n   - **Description:** A sleek and lightweight ultrabook for everyday use.\\n   - **Rating:** 4.5\\n\\n2. **BlueWave Gaming Laptop**\\n   - **Price:** $1,199.99\\n   - **Features:** 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\\n   - **Description:** A high-performance gaming laptop for an immersive experience.\\n   - **Rating:** 4.7\\n\\n3. **PowerLite Convertible**\\n   - **Price:** $699.99\\n   - **Features:** 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\\n   - **Description:** A versatile convertible laptop with a responsive touchscreen.\\n   - **Rating:** 4.3\\n\\n4. **BlueWave Chromebook**\\n   - **Price:** $249.99\\n   - **Features:** 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\\n   - **Description:** A compact and affordable Chromebook for everyday tasks.\\n   - **Rating:** 4.1\\n\\nDo any of these options catch your eye, or do you have specific requirements in mind, such as budget or intended use?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 324, 'prompt_tokens': 1452, 'total_tokens': 1776, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-cab80799-f23b-4e90-993e-c841b3a66cc9-0', usage_metadata={'input_tokens': 1452, 'output_tokens': 324, 'total_tokens': 1776, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "\n",
    "class ChatbotEvaluationIntention(BaseModel):\n",
    "    correct_intent: bool = Field(Literal[\"Product Information\", \"Product Comparison\", \"Product Recommendation\", \"Fallback\"], \n",
    "                                 description=\"Indicates if the predicted intent matches the correct intent, if none, it is a fallback case.\")\n",
    "    suggested_intent: Optional[str] = Field(\n",
    "        None, \n",
    "        description=\"Indicates if the predicted intent matches the correct intent. None indicates a fallback case.\"\n",
    "    )\n",
    "    response_quality: int = Field(\n",
    "        None,\n",
    "        ge=1, \n",
    "        le=5, \n",
    "        description=\"Rating of the chatbot's response quality, on a scale of 1 to 5.\"\n",
    "    )\n",
    "   # context_management: int = Field(\n",
    "   #     None,\n",
    "   #     ge=1, \n",
    "   #     le=5, \n",
    "   #     description=\"Rating of the chatbot's context management, on a scale of 1 to 5.\"\n",
    "   # )\n",
    "    feedback: str = Field(None, description=\"Small feedback on intent recognition, response quality, or context management, with suggestions for improvement.\")\n",
    "    fallback_case: bool = Field(\n",
    "        False, \n",
    "        description=\"Indicates if this instance is a fallback case where evaluation failed.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "output_parser = PydanticOutputParser(pydantic_object=ChatbotEvaluationIntention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "You are an expert evaluator for a task-specific chatbot. Your role is to assess the chatbot's performance by analyzing:\n",
    "1. Intent recognition accuracy.\n",
    "2. Response quality (clarity, relevance, and helpfulness).\n",
    "\n",
    "You will be provided with:\n",
    "- The most recent user query and the chatbot's predicted intent.\n",
    "- The chatbot's response to the latest user query.\n",
    "- A list of possible intentions with their detailed descriptions and examples.\n",
    "\n",
    "User Query: {user_query}\n",
    "Predicted Intent: {predicted_intent}\n",
    "Chatbot Response: {chatbot_response}\n",
    "Possible Intentions: {intent_list}\n",
    "\n",
    "### Your Task:\n",
    "1. **Intent Recognition**: Determine if the chatbot correctly identified the intent.\n",
    "2. **Response Quality**: Evaluate if the chatbot's response is appropriate, clear, and relevant.\n",
    "3. **Suggestions**: Recommend corrections for the intent or response if needed.\n",
    "\n",
    "### Evaluation Format:\n",
    "{format_instructions}\n",
    "\n",
    "### Tips for Ratings:\n",
    "- **Response Quality**: \n",
    "  - 5: Fully clear, relevant, and helpful.\n",
    "  - 3: Partially relevant or slightly unclear but generally acceptable.\n",
    "  - 1: Off-topic, confusing, or unhelpful.\n",
    "\n",
    "\n",
    "### Fallback Cases:\n",
    "If the evaluation cannot proceed due to invalid input or edge cases, follow these steps:\n",
    "1. Mark the case as a fallback by setting fallback_case to true.\n",
    "2. Set all other fields (correct_intent, suggested_intent, response_quality, context_management) to null or None.\n",
    "3. In the feedback field, explain clearly why the evaluation could not proceed. Examples include:\n",
    "    - The chatbot's response is incomprehensible or nonsensical.\n",
    "    - The user's intent is ambiguous or unclear.\n",
    "    - The conversation lacks sufficient context to evaluate the chatbot's response.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tiago\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\codeproject-WtLDeebZ-py3.11\\Lib\\site-packages\\pydantic\\json_schema.py:2191: PydanticJsonSchemaWarning: Default value typing.Literal['Product Information', 'Product Comparison', 'Product Recommendation', 'Fallback'] is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=system_template,\n",
    "    input_variables=[\"queuser_query\", \"predicted_intent\", \"chatbot_response\", \"intent_list\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.utils.pydantic.PromptInput"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_chain.input_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatbotEvaluationIntention(correct_intent=False, suggested_intent='Business Planning', response_quality=4, context_management=5, feedback=\"The predicted intent 'Product Information' does not match the user's intent of seeking a business plan. A more appropriate intent would be related to business planning or startup advice. The response is clear and relevant, asking for more details about the type of company, which helps in continuing the conversation effectively.\", fallback_case=False)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_chain.invoke({\"user_query\": \"I want a plan to create a company\", \"predicted_intent\": \"Product Information\",\n",
    "                          \"chatbot_response\": \"Sure, I can help you with that. What type of company are you looking to create?\",\n",
    "                            \"intent_list\": [\"Product Information\", \"Product Comparison\", \"Product Recommendation\", \"Fallback\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "# Define the intent classification template with chat history\n",
    "intent_classification_template = \"\"\"\n",
    "You are an expert classifier of user intentions. Your role is to accurately identify the user's intent based on:\n",
    "- The user's query.\n",
    "- The context provided in the conversation history.\n",
    "- A list of possible intentions with their detailed descriptions and examples.\n",
    "\n",
    "You will be provided with:\n",
    "- The user's query.\n",
    "- The conversation history up to the latest interaction.\n",
    "- A list of possible intentions.\n",
    "\n",
    "Conversation History: {conversation_history}  \n",
    "User Query: {user_query}  \n",
    "Possible Intentions: {intent_list}  \n",
    "\n",
    "Your task:  \n",
    "1. Analyze the user's query in the context of the conversation history and classify it into one of the possible intentions from the provided list.  \n",
    "2. If the query does not match any of the provided intentions, label it as 'Unclear Intent' and provide an explanation.  \n",
    "\n",
    "Output Format:  \n",
    "- Classified Intent: (The most suitable intent from the list or 'Unclear Intent')  \n",
    "- Explanation: (Why this intent was chosen or why the intent is unclear, referencing the conversation history if relevant)  \n",
    "\"\"\"\n",
    "\n",
    "class IntentClassification(BaseModel):\n",
    "    classified_intent: str = Field(Literal[\"Product Information\", \"Product Comparison\", \"Product Recommendation\", \"Unclear Fallback\"], description=\"The classified intent based on the user query.\")\n",
    "    explanation: str = Field(None, description=\"Explanation of the intent classification, including references to the conversation history.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Literal\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class Intent(BaseModel):\n",
    "\n",
    "    name: Literal[\"Product Information\", \"Product Comparison\", \"Product Recommendation\", \"Fallback\"] = Field(..., description=\"The name of the intent.\")\n",
    "\n",
    "    description: str = Field(..., description=\"A detailed description of the intent, including examples of user queries that match this intent.\")\n",
    "\n",
    "\n",
    "[\"Product Information\", \"Product Comparison\", \"Product Recommendation\", \"Fallback\"]\n",
    "\n",
    "\n",
    "\n",
    "product_info_intent = Intent(\"\"Product Information\", \"Get information about the products offered by the company, including features, pricing, and availability. Example queries: 'What products do you offer?' 'Can you tell me about your laptops?'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserIntentEvaluation(BaseModel):\n",
    "    # Literal for possible intents, including an extra 'fallback_case' for ambiguous cases\n",
    "    identified_intent: Literal[Intent] = Field(...,  description=\"The intent that best matches the user query, or 'fallback_case' if the intent is unclear or not part of the predefined options.\")\n",
    "\n",
    "    # Feedback with reasoning behind the intent decision\n",
    "    feedback: str = Field(..., description=\"A detailed explanation of why the identified intent was selected, considering the conversation history and user query.\")\n",
    "\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=UserIntentEvaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_intent_evaluation_template = \"\"\"\n",
    "You are an expert evaluator tasked with analyzing a user's intent based on their current input and previous conversation history.\n",
    "\n",
    "You will be provided with:\n",
    "- The conversation history up to the latest interaction.\n",
    "- The most recent user query.\n",
    "- A list of possible intentions with their detailed descriptions and examples.\n",
    "\n",
    "User Query: {user_query}\n",
    "Conversation History: {conversation_history}\n",
    "Possible Intentions: {intent_list}\n",
    "\n",
    "### Your Task:\n",
    "1. **Intent Evaluation**: \n",
    "   - Carefully review the conversation history along with the user query to determine the most likely user intent.\n",
    "   - Consider the context established by the previous interactions to identify the intent behind the current query.\n",
    "   - Choose the intent that best matches the user's query.\n",
    "\n",
    "2. **Matching Intent**:\n",
    "   - If the most likely intent is found in the provided list, identify it and provide the intent description.\n",
    "   - If none of the listed intents match the user query, select the 'Fallback' intent.\n",
    "\n",
    "### Evaluation Format:\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=user_intent_evaluation_template,\n",
    "    input_variables=[\"user_query\", \"conversation_history\", \"intent_list\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserIntentEvaluation(identified_intent='Fallback', feedback=\"The user query 'I want a plan to create a company' does not align with the previous conversation about product offerings and laptops. The previous interactions focused on product information and recommendations, while the current query indicates a desire for business planning, which is outside the scope of the provided intents.\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"user_query\": \"I want a plan to create a company\",\n",
    "                          \"conversation_history\": chat_history,\n",
    "                            \"intent_list\": [\"Product Information\", \"Product Comparison\", \"Product Recommendation\", \"Fallback\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeproject-WtLDeebZ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
